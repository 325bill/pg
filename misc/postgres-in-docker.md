# 容器中的数据库是一个好主意吗？

对于无状态的应用服务而言，容器是一个相当完美的开发运维解决方案。然而对于带持久状态的服务 —— 数据库来说，事情就没有那么简单了。作为一名开发者，我非常喜欢Docker，并相信Docker与Kubernetes就是未来软件开发部署运维的标准方式。但作为一名DBA，我认为容器里的数据库对于运维而言简直是一场噩梦。**生产环境的数据库**是否应当放入容器中，仍然是一个充满争议的问题。不过真理总是越辩越明的，今天我就来跟大家聊聊，为什么将生产环境数据库放入容器是一个馊主意。



## Docker解决什么问题？

让我们先来看一看Docker对自己的描述。

![docker-dev](../img/docker-dev.png)

![docker-ops](../img/docker-ops.png)

Docker用来形容自己的词语包括：轻量，标准化，可移植，节约成本，提高效率，自动，集成，高效运维。这些说法并没有问题，在整体意义上，Docker确实让开发和运维都变得更容易了。因此我们可以看到，很多公司都热切地希望将自己的软件与服务容器化。但有时候，这种热情会走向另一个极端：将一切软件都容器化，甚至是生产环境的数据库。

容器最初是针对无状态的应用而设计的，在逻辑上，容器内应用产生的临时数据也属于该容器的一部分。用容器创建起一个服务，用完之后销毁它。这些应用本身没有状态，状态通常保存在容器外部的数据库里，这是经典的架构与用法，也是容器的设计哲学。

但是当我们把数据库也放到容器里时，事情就变得不一样了。数据库是有状态的，为了维持这个状态不随容器停止而销毁，数据库容器需要打一个洞，与底层操作系统上的数据卷相联通。这样的容器，不再是一个能够随意创建，销毁，搬运，转移的对象，而与底层环境相绑定，因而传统应用容器的诸多优势，对于数据库容器来说都不复存在了。



## 可靠性

让软件跑起来和让软件可靠的运行是两回事。数据库是信息系统的核心，在绝大多数场景下属于关键应用（Critical），这里Critical的意思可以做字面解释：就是出了问题会要命。这与我们的日常经验相符：Word/Excel/PPT软件崩了大不了重启，但正在编辑的文档如果丢了脏了乱了，那才是真的噩梦。数据库亦然，对于很多公司而言，如果数据库被删了又没有备份，真的是可以关门大吉了。

可靠性是数据库最重要的属性。可靠性（reliability）是系统在**困境（adversity）**（硬件故障、软件故障、人为错误）中仍可正常工作（正确完成功能，并能达到期望的性能水准）的能力。注意可靠性不同于可用性（Availability），可靠性意味着**容错（fault-tolerant）**与**韧性（resilient）**。可用性通常可以使用一个由n个9组成的百分比值来衡量，代表系统可以正常提供服务时间的百分比。而可靠性往往并不能直接进行衡量，它只能通过长时间的正常运行来证明，或者某一次故障来否证。因此它属于一种**安全属性**，并不像性能与可维护性那样直观可衡量。安全生产重于泰山，很多人往往会忽视安全这个最重要的属性：人们通常只会在生病后，撞车后，被抢劫后，数据库被删后，才为忽视安全问题捶胸顿足，追悔莫及。 

回头再看一看，Docker对自己的描述中，并没有包含“可靠”这个对于数据库最为关键的重要属性，可谓很有自知之明。

### 额外失效点

相比裸机部署而言，将数据库放入容器中并不能降低硬件故障，软件错误，人为失误的发生概率。反而会因为**引入了额外的组件，额外的复杂度，额外的失效点，导致系统整体可靠性下降**。

数据库容器需要通过DataVolumn绑定到具体的机器上，因此裸机会有的硬件故障容器一个也不会少。标准化的部署方式看上去很美，但环境初始化命令写在脚本里和写在Dockerfile里也并没有本质区别，软件Bug主要是应用的Bug，也不会因为采用容器与否而降低，人为失误同理。

额外的组件引入额外的失效点，引入容器产生的问题并不仅仅是容器本身的问题。当故障发生时，它可能是数据库的问题，也可能是容器的问题，或者是两者之间交互产生的问题，还可能是操作系统与容器交互产生的问题。看一眼官方PostgreSQL Docker镜像的Issue列表就可以知道：https://github.com/docker-library/postgres/issues 。

举个最简单的例子，dockerd守护进程崩了怎么办，数据库进程就直接歇菜了。一个更微妙的例子是在同一个数据目录上启动了两个PostgreSQL实例，或者，在宿主机和容器里同时启动了两个数据库实例。在裸机上第二次启动会失败，而使用Docker数据卷则可以正常启动，工作在同一个数据目录上的两个Master实例会把数据搅成浆糊。尽管这些事情发生的概率并不高，但它们在裸机上**压根不会发生**。

### 可靠性证明与社区知识

正如前面所述，可靠性并没有一个很好的衡量方式。通过长期的正常运行，我们才能对一个系统的可靠性树立信心。在裸机上部署数据库可谓自古以来的实践，通过几十年的持续运转，它很好的证明了自己的可靠性。Docker虽为开发运维带来一场革命，但它仍然太年轻，仅仅五年的历史。对于关乎身家性命的生产数据库而言还远远不够：因为还没有足够的小白鼠去趟雷。

可靠性的提高，除了长时间的正常运行，另一种更为重要的方式就是故障。故障是非常宝贵的经验：它将未知问题变为已知问题，是运维知识的表现形式。社区经验绝大多都基于裸机部署的假设，各式各样的故障在几十年里都已经被人们踩了个遍。如果你遇到一些问题，大概率是别人已经踩过的坑，可以比较方便的处理与解决。可同样的故障如果再加上一个“Docker”关键字，能找到的有用信息就要少的多。这也意味着**当疑难杂症出现时，成功抢救恢复数据的概率要更低，处理紧急故障所需的时间会更长**。

一件很微妙的事情是，如果没有特殊理由，企业与个人通常并不愿意分享故障方面的经验。故障有损企业的声誉：可能暴露一些敏感信息，或者显示出企业的设施垃圾程度。另一方面，故障经验几乎都是真金白银的损失与学费换来的，也是运维人员的核心价值所在，愿意公开分享的个人并不多。因此有关这方面的公开资料非常之少。

### 工具

数据库需要工具来维护，包括各式各样的运维脚本，部署，备份，归档，Failover，大小版本升级，插件安装，连接池，性能分析，监控，调优，巡检，修复。这些工具，也大多针对裸机部署而设计。这些工具与数据库一样，都需要精心而充分的测试。**让一个东西跑起来，与确信这个东西能持久稳定正确的运行，是完全不同的可靠性水准。**

一个简单的例子是插件，PostgreSQL提供了很多实用的插件，譬如PostGIS。假如想为数据库安装该插件，在裸机上只要`yum install`然后`create extension postgis`两条命令就可以。但如果是在Docker里，按照the Docker practice，你需要修改Dockerfile，构建新镜像，推到服务器上，然后**重启数据库容器**。毫无疑问要麻烦的多。

类似的问题包括一些故障检测工具与系统常用命令，虽然理论上可以直接在宿主机上执行，但谁能保证容器里的结果和裸机上的结果有着相同的涵义？更为棘手的是紧急故障处理时，一些需要临时安装使用的工具在容器里没有，外网不通，如果再走Dockerfile→Image→重启这种路径毫无疑问会非常让人疯狂。

再比如说监控，在传统的裸机部署模式下，机器的各项指标是数据库指标的重要组成部分。容器中的监控与裸机上的监控有很多微妙的区别。不注意可能会掉到坑里。例如，CPU各种模式的时长之和，在裸机上始终会是100%，但这样的假设在容器中就不一定总是成立了。此外，如果涉及到与应用混部，监控管理还会有更大的麻烦。

在把Docker当成虚拟机来用的情况下，很多工具大抵还是可以确保正常工作的，只不过这样就丧失了使用的Docker的大部分意义，只是把Docker当成了包管理器用而已。这样的话就实在是大材小用得不偿失，又何必用容器呢？



## 可扩展性

### 性能

除了可靠性，性能是人们非常关注的另一个点。从性能方面出发，数据库的基本部署原则是离硬件越近越好，额外的隔离对于数据库是不好的。越多的隔离意味着越多的开销，即使只是内核栈中的额外拷贝。对于追求性能的场景，一些数据库选择绕开操作系统的页面管理机制直接操作磁盘，而一些数据库甚至会使用FPGA甚至GPU加速查询处理。

Docker作为一种轻量化的容器，性能上的折损还是在一个比较有限的范围内，对于性能不敏感的场景影响也许并不大。但容器这个额外抽象中间层毫无疑问会**对性能带来负面影响**而不是正面提升。

### 隔离性

Docker提供了进程级别的隔离性，数据库需要隔离性， 但不是这种隔离性。数据库的性能很重要，因此往往是独占物理机部署。除了数据库进程和必要的工具，不会有其他应用。即使放在容器中，也往往采用独占绑定物理机的模式运行。因此Docker提供的隔离性对于这种数据库部署方案而言并没有什么意义（但对云数据库厂商多租户超卖很有用）。

### 扩容

对于无状态的应用而言，使用容器让扩容变得无比简单，只要起几个新容器，随意调度到哪个节点都无所谓。但数据库不一样，作为一个有状态的应用，数据库并不能像普通AppServer一样随意创建销毁水平扩展：譬如创建一个新从库，即使使用容器，也得从主库上重新拉取。在生产环境中动辄几TB的数据库，也需要个把钟头才能完成，也仍然需要人工介入与检查。相比之下，在同样的操作系统初始环境下，运行现成的拉从库脚本与跑`docker run`在本质上又能有什么区别？时间都花在拖从库上了。

## 可维护性

软件的大部分开销并不在最初的开发阶段，而是在持续的维护阶段，包括修复漏洞、保持系统正常运行、处理故障、版本升级，偿还技术债、添加新的功能等等。可维护性对于运维人员的工作生活质量非常重要。应该说可维护性是Docker最讨喜的地方：Infrastructure as code。可以认为Docker的最大价值就在于它能够把软件的运维经验沉淀成可复用的代码，以一种简便的方式积累起来，而不再是散落在各个角落的install/setup文档。在这一点上，我认为Docker做的相当出色，尤其是对于逻辑经常变化的无状态应用而言。Docker和K8s能让我们轻松部署，完成扩容，缩容，发布，滚动升级等工作，让Dev也能干Ops的活，让Ops也能干DBA的活（说的和真的一样）。
	
但同样的结论能延伸到数据库上吗？数据库本身并不需要频繁的环境变动，一次初始化后，可能持续运行几年都不变。DBA们通常都会积攒有各种维护脚本，一键配置环境并不会比Docker慢多少，而且需要环境配置与初始化的次数相对而言实在太少了，因此容器在环境配置上的便利性并没有显著的优势。而对于日常运维而言，数据库容器不可能像应用容器一样随意销毁创建，重启迁移。很多操作都需要通过`docker exec`的方式执行：其实，跑的仍然是一样的脚本，只不过操作变得更为繁琐了。还是脱裤子放屁的问题。
	
举个例子：Docker喜欢说的事情是升级：例如用Docker升级数据库小版本，只要简单地修改Dockerfile里的版本号，重新构建镜像然后重启数据库容器就可以了。但是，当需要进行原地大版本升级时就抓瞎了，使用Docker原地二进制升级PostgreSQL的方式可能是这样的：https://github.com/tianon/docker-postgres-upgrade ，而同样的事情通过一行bash命令就可以解决。

很多命令行工具在Docker中使用起来都要麻烦的多，`docker exec`将`stderr`和`stdout`混在一起，让很多需要管道的命令无法正常工作，举个例子，一些ETL任务只需要简单的用下面一行bash搞定

```bash
psql <src-url> -c 'COPY tbl TO STDOUT' |\
psql <dst-url> -c 'COPY tdb FROM STDIN'
```

但如果用了Docker，这样的操作就变得复杂的多：

```bash
docker exec -it srcpg gosu postgres bash -c "psql -c \"COPY tbl TO STDOUT\" 2>/dev/null" |\ docker exec -i dstpg gosu postgres psql -c 'COPY tbl FROM STDIN;'
```

当你想为容器里的数据库做一个物理备份时，原本很简单的一条命令现在需要很多额外的包装：

```bash
docker exec -i postgres_pg_1 gosu postgres bash -c 'pg_basebackup -Xf -Ft -c fast -D - 2>/dev/null' | tar -xC /tmp/backup/basebackup
```

实际上，提升日常运维体验的并不是Docker，而是诸如ansible之类的工具。容器也许在搭建数据库环境上会更快，但这样的任务少到几乎可以忽略。因而，如果数据库容器不能像AppServer一样随意地调度，快速地扩展，也无法在初始配置，日常运维，以及紧急故障处理时相比普通脚本的方式带来更多便利性，我们又为什么要把生产环境的数据库塞进容器里呢？也许是因为没有专职DBA时，用一个粗糙的社区镜像部署也比瞎弄要强一些。
	
容器技术与编排技术对于运维而言是非常有价值的东西，它实际上弥补了从软件到服务之间的空白，其愿景是将运维的经验与能力代码化模块化。容器技术将成为未来的包管理方式，而编排技术将进一步发展为“数据中心分布式集群操作系统”，成为一切软件的底层基础设施Runtime。当越来越多的坑被踩完后，人们可以放心大胆的把一切应用，有状态的还是无状态的都放到容器中去运行。但现在，起码对于数据库而言，还只是一个美好的愿景。

## 总结

最后强调一下，以上讨论仅仅局限于**生产环境的数据库**。也就是说，对于开发环境而言，我对把数据库放入容器不仅没有任何意见，还会举双手赞成。对于生产环境的无状态应用，我也非常支持使用容器。但生产环境的数据库，如果这些数据真的很重要，使用容器还是得三思：愿意当小白鼠吗？能Hold住问题吗？锅背的动吗？

任何技术决策都是一个利弊权衡的过程，将生产数据库放入容器中，其核心权衡是**牺牲可靠性换取可维护性**。确实有一些场景，数据可靠性并不是那么重要，或者说有其他的考量：譬如对于云计算厂商来说，把数据库放到容器里混部超卖就是一件很好的事情：容器的隔离性，高资源利用率，以及管理上的便利性都与该场景十分契合。

但对于多数的场景而言，可靠性都是优先级最高的的属性，牺牲可靠性换取可维护性并不可取。更何况实际上运维管理数据库的工作并不会因为用了容器而轻松多少，反而更坚辛了。为了安装部署一次性的便利而牺牲长久的日常运维可维护性，并不是一个很好的买卖。

综上所述，我认为就目前而言，无论是利弊权衡，业界实践，团队准备程度而言，把生产环境的数据库放入容器中，给数据库戴套，实在是个馊主意。