# PostgreSQL的KPI

管数据库和管人差不多，都需要数据支撑，都要定KPI。那么数据库的KPI（关键性能指标）是什么？本文介绍了一种衡量PostgreSQL负载的方式：使用一种单一横向可比，与负载类型和机器类型无关的指标，名曰**PG Load（PG负载）。**



## 0x01 引言

在现实生产中，经常会有衡量数据库性能与负载，评估数据库水位的需求。一种最朴素的形式就是，能不能有一个类似于KPI的单一指标，能直接了当地告诉用户，他心爱的数据库负载有没有超过警戒线？工作量到底饱和不饱和？

当然这里其实隐含着一个重要信息，即用户期待的负载指标是一个**饱和度（Saturation）**指标，所谓饱和度，即服务容量有多”满“，通常是系统中目前最为受限的某种资源的某个具体指标的度量。通常来说，0%的饱和度意味着系统完全空闲，100%的饱和度意味着满载，系统在达到100%利用率前就会出现性能的严重下降，因此设定指标时还需要包括一个**利用率目标**，或者说**水位红线、黄线**，当系统瞬时负载超过红线时应当触发告警，长期负载超过黄线时应当进行扩容。

不幸的是，定义系统有多”饱和“并不是一件容易的事情，往往需要借助某些间接指标。评估一个数据库的负载程度，传统上通常会基于这样几类指标进行综合评估：

* 流量：每秒查询数量QPS，或每秒事务数量TPS。
* 延迟：查询平均响应时间 Query RT，或事务平均响应时间Xact RT

* 饱和度：机器负载（Load），CPU使用率，磁盘读写带宽饱和度，网卡IO带宽饱和度
* 错误：数据库客户端连接排队

这些指标对于数据库性能评估都很有参考意义，但它们也都存在各式各样的问题。



## 0x02 常用评估指标的问题

让我们来看一看，这些现有的常用指标都有哪些问题。

第一个Pass的当然是错误类指标，譬如连接池排队。错误类指标最大的问题就是，当错误出现时，饱和度可能已经没有意义了。**评估饱和度的一个重要原因就是用于预防系统过载，如果系统已经过载大量报错，那么使用错误现象反过来定义饱和度是没有意义的**。此外，错误类指标难以精确量化。我们只能说：当连接池出现排队时，数据库负载比较大；队列越长，负载越大；没有排队时，数据库负载不怎么大，仅此而已。这样的定义当然也无法让人满意。

第二个Pass的则是系统层（机器级别）指标，数据库运行在机器上，CPU使用率，IO使用率这样的指标与数据库负载程度密切相关，**如果CPU和IO是瓶颈，理论上当然是可以直接使用瓶颈资源的饱和度指标**作为数据库的饱和指标，但这一点并非总是成立的，有可能系统瓶颈在于数据库本身。而且严格来说它们是机器的KPI而不是DB的KPI，**评估数据库负载时当然可以参照系统层的指标，但DB层也应该有本层的评估指标**。要先有数据库本身的饱和度指标，才可以去比较底层资源和数据库本身到底谁先饱和谁是瓶颈。这条原则同样适用于应用层观察到的指标。

流量类的指标很有潜力，特别是QPS，TPS这样的指标相当具有代表性。但这些指标也存在问题。一个数据库实例上的查询往往是五花八门各式各样的，一个耗时10微秒的查询和一个10秒的查询在统计时都被算为一个Q，**类似于QPS这样的指标无法进行横向比较，只有比较粗略的参考意义**，甚至当查询类型发生变化时，都无法和自己的历史数据进行纵向比较。此外也很难针对QPS、TPS这样的指标设置利用率目标，同一个数据库执行`SELECT 1`可以打到几十万的QPS，但执行复杂SQL时可能就只能打到几千的QPS。不同负载类型和机器硬件会对数据库的QPS上限产生显著影响，只有当一个数据库上的查询都是高度单一同质且没有复杂变化的条件下，QPS才有参考意义，在这种苛刻条件下倒是可以通过压力测试设定一个QPS的水位目标。

比起QPS/TPS，RT（响应时间 Response Time）这样的指标反而更具有参考价值。因为响应时间增加往往是系统饱和的前兆。根据经验法则，数据库的负载越大，查询与事务的平均响应时间也会越高。RT相比QPS的一个优势是**，RT是可以设置一个利用率目标的**，比如可以为RT设定一个绝对阈值：不允许生产OLTP库上出现RT超过1ms的慢查询。但QPS这样的指标就很难画出红线来。不过，RT也有自己的问题。第一个问题是它依然是定性而非定量的，延迟增加只是系统饱和的预警，但没法用来精确衡量系统的饱和度。第二个问题通常能从数据库与中间件获取到的RT统计指标都是平均值，但真正起到预警效果的有可能是诸如P99，P999这样的统计量。

因此，这里把常用指标都批判了一番，到底什么样的指标适合作为数据库本身的饱和度呢？



## 0x03 它山之石，可以攻玉

我们不妨参考一下**机器负载（Node Load）**的评估指标是如何设计的。

想要看到机器的负载水平，在Linux中可以使用`top`命令。`top`命令的第一行输出就醒目地打印出当前机器1分钟，5分钟，15分钟的**平均负载水平**。

```bash
$ top -b1
top - 19:27:38 up 18:49,  1 user,  load average: 1.15, 0.72, 0.71
```

这里`load average`后面的三个数字分别表示最近1分钟，5分钟，15分钟系统的平均负载水平。

那么这个数字到底是什么意思呢？当然很好理解的是这个数字越大CPU越忙。

在单核CPU的场景下，Node Load（以下简称负载）是一个非常标准的饱和度指标。对于单核CPU，负载为0时CPU处于完全空闲的状态，负载为1（100%）时，CPU正好处于满负载工作的状态。负载大于100%时，超出100%部分比例的任务正在排队。

Node Load也有自己的**利用率目标**，通常的经验是在单核情况下：0.7（70%）是黄线，意味着系统有问题，需要尽快检查；1.0（100%）是红线，负载大于1意味着进程开始堆积，需要立即着手处理。5（500%）是死线，意味着系统基本上已经堵死了。

对于多核CPU，事情稍微有点不一样。假设有n个核，那么当系统负载为n时，所有CPU都处于满载工作的状态；而当系统负载为n/2时，姑且可以认为一半CPU核正在满载运行。因而48核CPU的机器满载时的负载为48。总的来说，如果我们把机器负载除以机器的CPU核数，得到的指标就与单核场景下保持一致了（0%空载，100%满载）。

那么Node Load是怎么计算出来的呢？假设CPU每秒可以处理100个任务，那么1.5（150%）的负载意味着有50个进程正在排队。



## QPS x RT

我们不妨参考一下机器负载的评估指标Load Avg是如何设计的。

### Node Load的定义

Linux `top`命令的第一行就会醒目地打印出当前机器1分钟，5分钟，15分钟的**负载**。

```
$ top -b1
top - 19:27:38 up 18:49,  1 user,  load average: 1.15, 0.72, 0.71
```

那么这个**负载（Load）**到底是什么意思呢？当然很好理解的是这个数字越大CPU越忙。

更定量一点的解释是，对于单核CPU，负载为0时CPU处于完全空闲的状态，负载为1时，CPU正好处于满负载工作的状态。负载大于1时，超出1部分比例的任务正在排队。对于多核CPU，假设有n个核，那么当系统负载为n时，所有CPU都处于满载工作的状态。



那么对于PG的负载，我们自然会想到是不是也可以采用类似的办法来定义？当然，而且这是一个极棒的主意。

让我们先来考虑单进程情况下的PG负载，假设我们也需要这样一个指标，当该PG进程完全空闲时负载因子为0，当该进程处于满载状态时负载为1（100%）。那么根据定义，我们会自然而然的想到，直接使用PG活跃时长就可以了。即对于某个时间段（1分钟，5分钟，15分钟）来说，单进程PG负载可以定义为：

该时间段内PG处于活跃忙碌状态的时长 / 该时间段时长

那么针对多进程的情况，可以推广为：

该时间段内所有PG进程处于活跃/忙碌状态的总时长  / （可用并发数 * 该时间段时长）

PG总活跃时长很好理解，假设这里的统计时间段为最近一分钟，且当前机器最大支持两个PG进程并发执行。如果A进程在这一分钟内有30秒处于忙碌状态，B进程在这一分钟里有10秒处于忙碌状态。那么这个PG实例最近一分钟的负载为：

(30+10) / (2*60) = 40 / 120 =  33.33%

那么这个指标定义的真正问题在于：PG总活跃时长，与可用并发数，这两个值怎么获取或估算。幸运的是这两个问题都很好解决。

所有PG后端进程处于活跃状态的总时长，这个数据是没法通过PG本身获取的，因为PG本身提供的统计视图里并没有这个统计项，你只能看到某个时间节点上PG所有进程的状态快照，但无法知道一个时间段内处于活跃状态的时长。好在我们可以通过查询中间件解决这个问题，Pgbouncer是一个轻量的PG连接池，可以从中获取到这个指标：

* `pgbouncer_stat_total_xact_time` 连接处于事务中状态的总耗时
* `pgbouncer_stat_total_query_time` 连接处于查询状态的总耗时

在没有交互式事务的情况下，两种指标结果几乎完全相同。因为连接处于事务中，并不意味着连接一定正忙着执行查询，它也可能正在闲着。因此使用查询总时长会比事务总时长更精确，使用事务总时长会倾向于高估负载。不过这里，我们仍然采用事务的总耗时作为活跃时长的标准，因为Idle In Transaction也不是什么好事，标准严一点比宽一点要好。

那么很简单，只需要让该指标对时间求导，`rate(pgbouncer_stat_total_xact_time)`，我们就可以获取每秒钟的PG活跃总时长了。

注意因为并发的存在，可能有多个进程同时处于活跃状态，它们的活跃时长之和会累加起来。因此这里的每秒活跃总时长（活跃时间总占比）是可能大于1秒的，所以还要除以可用并发数进行归一化。这里就引出了第二个问题，可用并发数的问题。

可用并发数我们可以简单的采用CPU的核数进行计算。因此，最后得到的指标计算规则就是：

`irate(pgbouncer_stat_total_xact_time{}[1m]) / node:ins:cpu_count`



```yaml
# 每秒活跃的总时长
- record: pg:ins:xact_time_rate1m
expr: sum without (datname) (rate(pgbouncer_stat_total_xact_time{}[1m])) / 1000000
- record: pg:ins:xact_time_rate5m
expr: sum without (datname) (rate(pgbouncer_stat_total_xact_time{}[5m])) / 1000000
- record: pg:ins:xact_time_rate15m
expr: sum without (datname) (rate(pgbouncer_stat_total_xact_time{}[15m])) / 1000000

# 实例级别的Load
- record: pg:ins:load0
expr: sum without (datname) (irate(pgbouncer_stat_total_xact_time{}[1m])) / on (ip) group_left()  node:ins:cpu_count / 1000000
- record: pg:ins:load1
expr: pg:ins:xact_time_rate1m  / on (ip) group_left()  node:ins:cpu_count
- record: pg:ins:load5
expr: pg:ins:xact_time_rate5m  / on (ip) group_left()  node:ins:cpu_count
- record: pg:ins:load15
expr: pg:ins:xact_time_rate15m  / on (ip) group_left()  node:ins:cpu_count

# 集群级别的Load
- record: pg:cls:load0
expr: sum by (cls) (irate(pgbouncer_stat_total_xact_time{}[1m])) / on (cls) node:cls:cpu_count{} / 1000000
- record: pg:cls:load1
expr: sum by (cls) (pg:ins:xact_time_rate1m)  / on (cls) node:cls:cpu_count
- record: pg:cls:load5
expr: sum by (cls) (pg:ins:xact_time_rate5m)  / on (cls) node:cls:cpu_count
- record: pg:cls:load15
expr: sum by (cls) (pg:ins:xact_time_rate15m)  / on (cls) node:cls:cpu_count

```







## TL;DR

某个时间段的PG负载定义：

该时间段内所有PG后端进程处于活跃状态的总时长 / (可用并发数 * 时间段长度)

`irate(pgbouncer_stat_total_xact_time{}[1m]) / node:ins:cpu_count`

该指标可以有效衡量PG的负载水平，可以横向对比，无需考虑具体查询负载类型与宿主机器规格，以直观的单一百分比指标展示PG的忙碌程度，与机器负载采用类似的定义方式，容易理解。可用于系统报警，容量评估，性能优化等场景，效果拔群。









首先是基于硬件与操作系统的指标，例如CPU磁盘网卡使用率，这些指标都很实用，但严格意义上说它们都是系统层的性能评估指标。评估数据库性能时当然可以参照系统层的指标，但DB层也必须有本层的评估指标。

QPS，或者TPS，是一个相当具有代表性的指标，但用于系统负载评估也有着巨大的问题。第一是数据库中的每个查询或者每个事务并**不一定是同质化**的。Q和Q是不一样的，有的查询可能只要几十微秒，而另一些查询则可能需要几毫秒。同一个数据库，执行SELECT 1可能打到几十万的QPS，但复杂事务查询的上限就可能只有几万了。不同负载类型和机器硬件会对QPS上限产生显著影响，从这个角度看，QPS这类指标不具有横向可比性。某种意义上来说，也无法成为一个真正意义上的评估指标。

RT则是另一个重要的指标，不幸的是单纯使用RT也存在同样的问题。线上数据库的实际查询可能各式各样，而不同的查询有着不同的响应时间，平均响应时间并无法反映出请求RT的分布情况。不过比起QPS要好一点的是，平均查询响应时间是可以横向比较并画出红线的，比如在生产环境OLTP库中可以画一条RT的红线：不允许出现超过1ms的慢查询，但QPS这样的指标就很难画出一条红线出来。

此外，无论是QPS还是RT，它们都与具体的负载类型有关系。因此，不同的数据库实例之间无法使用这两种指标来横向比较相对负载大小。

那么，何解？怎么样设计一个指标来解决上面的问题呢？

